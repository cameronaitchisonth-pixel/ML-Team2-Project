{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Volatility Forecasting Model \u2014 Random Forest\n",
        "**Author:** Dipak G. Sakharkar\n\n",
        "Forecasts next-day realized volatility of S&P 500 index using a time-aware Random Forest approach.\n",
        "- Target: Next-day 5-day realized volatility (annualized)\n",
        "- Evaluation: Walk-forward TimeSeriesSplit (RMSE, MAE, R\u00b2)\n",
        "- Features: Lag, rolling statistics, and volatility measures\n",
        "- Implementation: Leakage-free, reproducible, and saved metrics/feature importances\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "# Inline Plot Test\n",
        "plt.figure(); plt.plot([0,1,0]); plt.title('Inline Plot Test'); plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "# --- Setup (Verbose)\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport math, os, glob\n\nprint(\"[step] Setup imports loaded.\")\n\npd.set_option('display.width', 120)\npd.set_option('display.max_columns', 50)\n\n# Config\nVOL_WINDOW = 5      # realized volatility window (days)\nN_SPLITS   = 5      # time-series CV folds\nRF_PARAMS  = dict(n_estimators=600, max_depth=None, min_samples_leaf=2, max_features='sqrt', random_state=42, n_jobs=-1)\nRECENT_N   = None   # set to e.g. 4000 to speed experiments; None = all\n\nprint(f\"[config] VOL_WINDOW={VOL_WINDOW}, N_SPLITS={N_SPLITS}, RF_PARAMS={RF_PARAMS}, RECENT_N={RECENT_N}\")\n\ndef candidate_paths():\n    cwd = Path.cwd()\n    env_dir = os.environ.get(\"DATA_PATH\")\n    paths = []\n    if env_dir:\n        paths += [\n        cwd.parent/'data'/'SPX.csv',  # Added to match Richard's structure\nPath(env_dir)/\"SPX.csv\"]\n    paths += [\n        cwd.parent/'data'/'SPX.csv',  # Added to match Richard's structure\n\n        cwd/'SPX.csv',\n        cwd/'data'/'SPX.csv',\n        cwd.parent/'data'/'SPX.csv',\n        Path('/mnt/data/SPX.csv'),\n        Path('/mnt/data/SPX-checkpoint.csv'),\n    ]\n    globs = []\n    for pat in ['SPX*.csv', 'spx*.csv', '*SP500*.csv', '*S&P*.csv']:\n        globs += list(cwd.glob(pat))\n        if (cwd/'data').exists():\n            globs += list((cwd/'data').glob(pat))\n    paths += globs\n    # de-dup\n    seen=set(); out=[]\n    for p in paths:\n        key = str(p.resolve()) if p.exists() else str(p)\n        if key not in seen:\n            out.append(p); seen.add(key)\n    return out\n\ndef load_spx():\n    print(\"[data] Searching for SPX.csv ...\")\n    checks = []\n    for p in candidate_paths():\n        checks.append(str(p))\n        try:\n            if p.exists() and p.is_file():\n                df = pd.read_csv(p)\n                df.columns = [c.strip().title().replace(' ', '') for c in df.columns]\n                price_col = 'Adjclose' if 'Adjclose' in df.columns else ('AdjClose' if 'AdjClose' in df.columns else ('Close' if 'Close' in df.columns else None))\n                if price_col is None:\n                    continue\n                px = pd.to_numeric(df[price_col], errors='coerce').dropna()\n                if len(px) > 100:\n                    print(f\"[data] Loaded {len(px)} rows from: {p}\")\n                    return px\n        except Exception as e:\n            pass\n    print(\"[data] Checked paths:\")\n    for p in checks: print(\"   -\", p)\n    raise FileNotFoundError(\"SPX.csv not found in the above locations. Place it next to this notebook, in ./data, or set DATA_PATH.\")\n\npx = load_spx()\nif RECENT_N:\n    px = px.iloc[-RECENT_N:]\nprint(f\"[ok] Data ready. Length: {len(px)}\")\nlen(px)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Target and Features (aligned)\n",
        "We model **log-volatility** and back-transform for evaluation. All predictors are aligned so that only information available **up to time t** is used to predict **t+1**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Target & features (Verbose)\nprint(\"[step] Building target and features ...\")\nret = np.log(px/px.shift(1))\nvol = pd.Series(ret).rolling(VOL_WINDOW).std() * np.sqrt(252)\n\ny_raw = vol.shift(-1)\ny_log = np.log(y_raw.clip(lower=1e-10))\n\ndef rsum(r, w): return pd.Series(r).rolling(w).sum()\ndef rstd(r, w): return pd.Series(r).rolling(w).std()\ndef rmean(r, w): return pd.Series(r).rolling(w).mean()\n\nX = pd.DataFrame({\n    'ret_1': pd.Series(ret).shift(1),\n    'ret_5_sum': rsum(ret,5).shift(1),\n    'ret_5_std': rstd(ret,5).shift(1),\n    'ret_21_std': rstd(ret,21).shift(1),\n    'ret_21_mean': rmean(ret,21).shift(1),\n    'vol_t': vol,\n    'vol21_t': pd.Series(ret).rolling(21).std() * np.sqrt(252),\n    'ret_abs_1': pd.Series(ret).abs().shift(1),\n    'ret_sq_1': (pd.Series(ret)**2).shift(1),\n}).dropna()\n\naligned = pd.concat([X, y_log], axis=1).dropna()\nX, ylog = aligned[X.columns], aligned[y_log.name]\n\nprint(f\"[ok] Features/target ready. X shape: {X.shape}, ylog shape: {ylog.shape}\")\nprint(\"[peek] X.head():\") \ndisplay(X.head())\nprint(\"[peek] ylog.head():\") \ndisplay(ylog.head())\n\nX.shape, ylog.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Walk-forward evaluation (TimeSeriesSplit)\n",
        "We report RMSE/MAE/R\u00b2 on the **original volatility scale** (after back-transform)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def walkforward_scores(X, ylog, n_splits=5, rf_params=None):\n    if rf_params is None:\n        rf_params = RF_PARAMS\n    cv = TimeSeriesSplit(n_splits=n_splits)\n    rmse, mae, r2 = [], [], []\n    rows = []\n    for k, (tr, va) in enumerate(cv.split(X), 1):\n        Xtr, Xva = X.iloc[tr], X.iloc[va]\n        ytr, yva = ylog.iloc[tr], ylog.iloc[va]\n        rf = RandomForestRegressor(**rf_params)\n        rf.fit(Xtr, ytr)\n        pred = np.asarray(np.exp(rf.predict(Xva)), dtype=float)\n        true = np.asarray(np.exp(yva), dtype=float)\n        rmse_k = float(np.sqrt(mean_squared_error(true, pred)))\n        mae_k = float(mean_absolute_error(true, pred))\n        ybar = float(true.mean())\n        ss_res = float(((true - pred)**2).sum())\n        ss_tot = float(((true - ybar)**2).sum())\n        r2_k = float(1 - ss_res/ss_tot) if ss_tot > 0 else float('nan')\n        rmse.append(rmse_k); mae.append(mae_k); r2.append(r2_k)\n        rows.append({'fold': k, 'rmse': rmse_k, 'mae': mae_k, 'r2': r2_k,\n                     'n_train': int(len(tr)), 'n_val': int(len(va))})\n    summary = {\n        'rmse_mean': float(np.mean(rmse)), 'rmse_std': float(np.std(rmse)),\n        'mae_mean': float(np.mean(mae)),   'mae_std': float(np.std(mae)),\n        'r2_mean': float(np.nanmean(r2))\n    }\n    return pd.DataFrame(rows), summary\n\nprint('[step] Running walk-forward evaluation ...')\nfold_df, summary = walkforward_scores(X, ylog, n_splits=N_SPLITS, rf_params=RF_PARAMS)\nprint('[ok] CV complete. Summary:')\nprint(summary)\ndisplay(fold_df)\n# Save artifacts\noutdir = Path('experiments/results')\noutdir.mkdir(parents=True, exist_ok=True)\nfold_df.to_csv(outdir/'revF_cv_folds.csv', index=False)\npd.Series(summary).to_csv(outdir/'revF_cv_summary.csv')\nprint(f\"[saved] {outdir/'revF_cv_folds.csv'}\\n[saved] {outdir/'revF_cv_summary.csv'}\")\nsummary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit final model on full data\n",
        "Use the configured RF on all available samples. You can later serialize the model if needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Prediction vs Actual (last fold) and Residuals ---\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\n\ncv = TimeSeriesSplit(n_splits=5)\nlast_tr, last_va = list(cv.split(X))[-1]\nrf = RandomForestRegressor(**RF_PARAMS)\nrf.fit(X.iloc[last_tr], ylog.iloc[last_tr])\npred = np.exp(rf.predict(X.iloc[last_va]))\ntrue = np.exp(ylog.iloc[last_va])\n\nplt.figure(figsize=(8,4))\nplt.plot(true.values, label='Actual', alpha=0.7)\nplt.plot(pred, label='Predicted', alpha=0.7)\nplt.title('Predicted vs Actual Volatility (Last Fold)')\nplt.legend()\nplt.tight_layout()\nfrom pathlib import Path\noutdir = Path('experiments/results'); outdir.mkdir(parents=True, exist_ok=True)\nplt.savefig(outdir/'rev5_pred_vs_actual.png')\nplt.show()\n\n# Residuals plot\nresid = true - pred\nplt.figure(figsize=(8,3))\nplt.plot(resid.values)\nplt.title('Residuals Over Time (Last Fold)')\nplt.tight_layout()\nfrom pathlib import Path\noutdir = Path('experiments/results'); outdir.mkdir(parents=True, exist_ok=True)\nplt.savefig(outdir/'rev5_residuals.png')\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "final_model = RandomForestRegressor(**RF_PARAMS).fit(X, ylog)\nfi = pd.Series(final_model.feature_importances_, index=X.columns).sort_values(ascending=False)\nprint(\"[ok] Final model trained. Top features:\")\ndisplay(fi.head(15).to_frame(\"importance\"))\n# Save\noutdir = Path('experiments/results')\noutdir.mkdir(parents=True, exist_ok=True)\nfi.to_csv(outdir/'revF_feature_importance.csv', header=True)\nprint(f\"[saved] {outdir/'revF_feature_importance.csv'}\")\nfi.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Plot Feature Importances ---\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(6,4))\nfi.head(15).iloc[::-1].plot(kind='barh')\nplt.title('Top 15 Feature Importances')\nplt.xlabel('Importance')\nplt.tight_layout()\n\nfrom pathlib import Path\noutdir = Path('experiments/results'); outdir.mkdir(parents=True, exist_ok=True)\nplt.savefig(outdir/'rev5_feature_importance.png')\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# param_dist = {\n",
        "#     'n_estimators': [300, 600, 900],\n",
        "#     'max_depth': [None, 6, 10, 14],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'max_features': ['sqrt', 0.5, 0.75],\n",
        "# }\n",
        "# cv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
        "# search = RandomizedSearchCV(RandomForestRegressor(random_state=42, n_jobs=-1),\n",
        "#                             param_distributions=param_dist, n_iter=20,\n",
        "#                             scoring='neg_root_mean_squared_error', cv=cv,\n",
        "#                             random_state=42, n_jobs=-1)\n",
        "# search.fit(X, ylog)\n",
        "# search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Plot Feature Importances (uses trained model or saved CSV) ---\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "fi = None\n",
        "try:\n",
        "    fi = pd.Series(final_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "except Exception:\n",
        "    # Fall back to CSV produced earlier versions\n",
        "    outdir = Path('experiments/results')\n",
        "    csv_path = outdir/'revL_feature_importance.csv'\n",
        "    if csv_path.exists():\n",
        "        tmp = pd.read_csv(csv_path)\n",
        "        if tmp.shape[1] >= 2:\n",
        "            fi = pd.Series(tmp.iloc[:,1].values, index=tmp.iloc[:,0].values).sort_values(ascending=False)\n",
        "if fi is not None:\n",
        "    display(fi.head(15).to_frame('importance'))\n",
        "    plt.figure(figsize=(6,4))\n",
        "    fi.head(15).iloc[::-1].plot(kind='barh')\n",
        "    plt.title('Top 15 Feature Importances')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.tight_layout(); plt.show()\n",
        "else:\n",
        "    print('Feature importance not available \u2014 run the training cell first.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Predicted vs Actual & Residuals (last fold) ---\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "try:\n",
        "    cv = TimeSeriesSplit(n_splits=5)\n",
        "    last_tr, last_va = list(cv.split(X))[-1]\n",
        "    model = RandomForestRegressor(**RF_PARAMS)\n",
        "    model.fit(X.iloc[last_tr], ylog.iloc[last_tr])\n",
        "    pred = np.exp(model.predict(X.iloc[last_va]))\n",
        "    true = np.exp(ylog.iloc[last_va])\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(true.values, label='Actual', alpha=0.85)\n",
        "    plt.plot(pred, label='Predicted', alpha=0.85)\n",
        "    plt.title('Predicted vs Actual Volatility (Last Fold)')\n",
        "    plt.legend(); plt.tight_layout(); plt.show()\n",
        "    resid = true - pred\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.plot(resid.values)\n",
        "    plt.title('Residuals Over Time (Last Fold)')\n",
        "    plt.tight_layout(); plt.show()\n",
        "except Exception as e:\n",
        "    print('Run the data/feature/training cells first \u2014 plotting skipped. Error:', e)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}